# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- master
stages:
  - stage: Gather_data

    jobs:
      - job: 'ScrapeGit'

        strategy:
          parallel: 4 # This number should be less than or equal to the number of lines in sample.txt

        pool:
          vmImage: 'ubuntu-latest'

        steps:
        - script: |
            source scripts/installGithubScrapping.sh
            echo "Will scrape:"
            cat scripts/sample/sample.txt | slicer.sh $(System.JobPositionInPhase)  $(System.TotalJobsInPhase)
            echo
            cat scripts/sample/sample.txt | slicer.sh $(System.JobPositionInPhase)  $(System.TotalJobsInPhase)   |  gitReports.sh - '2 years ago' 'today'
          displayName: 'Git Scrape'

        - task: PublishPipelineArtifact@1
          inputs:
            targetPath: 'gitReports'
            artifact: 'GitReports-$(System.JobPositionInPhase)'
            publishLocation: 'pipeline'

  - stage: Aggregate_Data
    jobs:
      - job: Aggregate

        pool:
          vmImage: 'ubuntu-latest'

        steps:
          - task: DownloadPipelineArtifact@2
            inputs:
              path: rawData

          - script: |
              ls gitReports
            displayName: 'debug'
          - script: |
              find rawData -name gitReports | xargs -L1 cat | tee result
            displayName: 'aggregate'

          - task: PublishPipelineArtifact@1
            inputs:
              targetPath: 'result'
              artifact: "Results"
              publishLocation: 'pipeline'
            displayName: 'Publish results'
